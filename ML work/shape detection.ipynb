{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def detect(self, c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "        # if the shape is a triangle, it will have 3 vertices\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    " \n",
    "        # if the shape has 4 vertices, it is either a square or\n",
    "        # a rectangle\n",
    "        elif len(approx) == 4:\n",
    "        # compute the bounding box of the contour and use the\n",
    "        # bounding box to compute the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    " \n",
    "        # a square will have an aspect ratio that is approximately\n",
    "        # equal to one, otherwise, the shape is a rectangle\n",
    "            shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    " \n",
    "        #if the shape is a pentagon, it will have 5 vertices\n",
    "    \n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    " \n",
    "        # otherwise, we assume the shape is a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    " \n",
    "        # return the name of the shape\n",
    "        return shape\n",
    "\n",
    "cnts = contours[0] if imutils.is_cv2() else contours[1]\n",
    "sd = ShapeDetector()\n",
    "sd.detect(cnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhash\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('C://Users//DU357159//Documents//ENU_DATA//data//Sismic//images (17).jpg')\n",
    "\n",
    "row, col = dhash.dhash_row_col(image)\n",
    "hash1 = dhash.format_hex(row, col)\n",
    "len(bin(int(hash1, 16)))\n",
    "\n",
    "image = Image.open('C://Users//DU357159//Documents//ENU_DATA//data/Maps//images (7).jpg')\n",
    "row, col = dhash.dhash_row_col(image)\n",
    "hash2 = dhash.format_hex(row, col)\n",
    "bin(int(hash2,16))\n",
    "\n",
    "#dhash.get_num_bits_different(bin(int(hash1, 16)) ,bin(int(hash2, 16)))\n",
    "\n",
    "def hamming2(s1, s2):\n",
    "    \"\"\"Calculate the Hamming distance between two bit strings\"\"\"\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification with Numpy and GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdalnumeric\n",
    "\n",
    "\n",
    "# Input file name (thermal image)\n",
    "src = 'C://Users//DU357159//Documents//ENU_DATA//data//Sismic//720483274_2000692456_WDF0000242.tif_Resize.tif'\n",
    "\n",
    "# Output file name\n",
    "tgt = \"C://Users//DU357159//Documents//ENU_DATA//data//classified.jpg\"\n",
    "\n",
    "# Load the image into numpy using gdal\n",
    "srcArr = gdalnumeric.LoadFile(src)\n",
    "\n",
    "# Split the histogram into 20 bins as our classes\n",
    "classes = gdalnumeric.numpy.histogram(srcArr, bins=20)[1]\n",
    "\n",
    "# Color look-up table (LUT) - must be len(classes)+1.\n",
    "# Specified as R,G,B tuples \n",
    "lut = [[255,0,0],[191,48,48],[166,0,0],[255,64,64],\n",
    "[255,115,115],[255,116,0],[191,113,48],[255,178,115],\n",
    "[0,153,153],[29,115,115],[0,99,99],[166,75,0],\n",
    "[0,204,0],[51,204,204],[255,150,64],[92,204,204],[38,153,38],\n",
    " [0,133,0],[57,230,57],[103,230,103],[184,138,0]]\n",
    "\n",
    "# Starting value for classification\n",
    "start = 1\n",
    "\n",
    "# Set up the RGB color JPEG output image\n",
    "rgb = gdalnumeric.numpy.zeros((3, srcArr.shape[0],\n",
    "srcArr.shape[1],), gdalnumeric.numpy.float32)\n",
    "       \n",
    "# Process all classes and assign colors\n",
    "for i in range(len(classes)):\n",
    "    mask = gdalnumeric.numpy.logical_and(start <=srcArr, srcArr <= classes[i])\n",
    "    for j in range(len(lut[i])):\n",
    "        rgb[j] = gdalnumeric.numpy.choose(mask, (rgb[j], lut[i][j]))\n",
    "    start = classes[i]+1 \n",
    "\n",
    "# Save the image    \n",
    "gdalnumeric.SaveArray(rgb.astype(gdalnumeric.numpy.uint8), tgt, format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4702, 3385, 3)\n",
      "(8480, 6183, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2,os,sys,glob\n",
    "import random\n",
    "\n",
    "def crop_image_part(filename):\n",
    "    #reading the image \n",
    "    image = cv2.imread(filename)\n",
    "    #Applying Canny Edge Detection\n",
    "    edges = cv2.Canny(image, 10, 250) \n",
    "    #applying closing function \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    #Dilation follwed by erosion\n",
    "    closed_image = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    #Finding_contours \n",
    "    (_,cnts, _) = cv2.findContours(closed_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    idx = 0\n",
    "    #Crop the image that has width and height greater than 500\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w>500 and h>1000:\n",
    "            idx+=1\n",
    "            new_img=image[y:y+h,x:x+w]\n",
    "            print(new_img.shape)\n",
    "            if new_img.shape[0]/new_img.shape[1] > 1:\n",
    "                cv2.imwrite(filename +'_' + str(idx) + '.jpg', new_img)\n",
    "\n",
    "#Driver function to load the image folder or a single image\n",
    "#Example usuage : python contour_analysis.py folder_name\\* or python contour_analysis.py folder_name\\seismic.tif\n",
    "file_name = 'C:\\\\Users\\\\DU357159\\\\Documents\\\\ENU_DATA\\\\Not resized\\\\720483274_2000692457_WDF0000243.tif'\n",
    "crop_image_part(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
